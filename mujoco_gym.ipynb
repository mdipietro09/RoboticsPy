{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f91ab3c1-1426-4321-a39f-6cdfd823f91b",
   "metadata": {},
   "source": [
    "# Robotics with Python: MuJoCo & Gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ae8c9e-1ca3-4c28-92db-1983f73b2ec2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec626f0d-ed53-4a61-9dd0-3db68228373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install mujoco\n",
    "#pip install gymnasium\n",
    "\n",
    "import gymnasium as gym\n",
    "import time\n",
    "\n",
    "env = gym.make(\"Humanoid-v4\", render_mode=\"human\")\n",
    "obs, info = env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6518852-f8f7-47bc-9c3a-b04fb9009e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_position': np.float64(0.0016152704880662335),\n",
       " 'y_position': np.float64(-0.006376264384969079),\n",
       " 'tendon_length': array([ 0.0039346 , -0.00659782]),\n",
       " 'tendon_velocity': array([-0.00065977,  0.00110333]),\n",
       " 'distance_from_origin': np.float64(0.006577677877233183)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed678fa4-f2a3-4d06-ad04-70f2e0fa6b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.40551438e+00,  1.00249109e+00,  1.02295992e-03,  6.11636741e-03,\n",
       "        8.89343991e-03,  3.68799654e-03,  2.68748631e-03, -7.37148320e-03,\n",
       "       -1.27035634e-03, -3.83448487e-03,  4.97995726e-03, -9.27465782e-04,\n",
       "       -5.30276103e-03, -6.80604484e-04, -9.18529355e-03, -1.14950454e-03,\n",
       "       -7.01506517e-03,  3.62228355e-03,  8.04498421e-03, -5.30207130e-03,\n",
       "       -1.90562795e-03, -6.06947519e-05,  2.28593828e-05,  6.61675641e-03,\n",
       "        9.77447190e-03, -6.79145658e-03,  9.35076611e-03,  9.40259276e-03,\n",
       "        6.24602486e-03, -7.69409031e-03,  7.79339588e-03, -3.57860426e-03,\n",
       "        8.84452451e-03,  2.14833940e-03,  3.15900130e-03, -3.69123743e-03,\n",
       "        5.47496853e-03,  3.01387670e-03,  9.26404279e-03, -1.41988753e-03,\n",
       "        1.43547743e-03, -1.56219701e-03,  6.16717799e-03,  5.88406125e-03,\n",
       "        6.06353189e-03,  2.30359698e+00,  2.28564819e+00,  4.23921394e-02,\n",
       "        3.81892603e-04,  4.27251199e-02, -1.34221053e-03, -9.78046855e-02,\n",
       "        3.05445261e-03,  4.35635947e+00,  8.90746237e+00,  9.54401200e-02,\n",
       "        9.04533260e-02,  1.09705672e-02,  1.69755818e-04,  9.77440278e-03,\n",
       "       -3.54790130e-04, -5.02470996e-02,  1.75551967e-03,  4.39996214e-01,\n",
       "        2.26194671e+00,  5.81292177e-02,  4.29646789e-02,  6.51220250e-02,\n",
       "        5.80889417e-04,  8.63263977e-03,  1.58756505e-04, -2.91065012e-01,\n",
       "       -4.52640715e-04,  1.96299323e-01,  6.61619413e+00,  2.72599949e-01,\n",
       "        2.31594969e-01,  5.48173694e-02, -1.10165227e-02, -2.15081603e-02,\n",
       "       -8.05523997e-02, -1.14986334e-01, -4.56016698e-01, -8.55144168e-01,\n",
       "        4.75175093e+00,  9.30058281e-01,  9.08257704e-01,  2.96113625e-02,\n",
       "       -7.45843650e-03, -4.52459751e-02, -1.45304611e-01, -7.97117497e-02,\n",
       "       -2.57757649e-01, -1.55134593e+00,  2.75569617e+00,  1.04849763e+00,\n",
       "        1.03433793e+00,  2.16319803e-02, -5.27336804e-03, -4.24042258e-02,\n",
       "       -1.27917885e-01, -5.55800809e-02, -1.67664573e-01, -1.34822496e+00,\n",
       "        1.76714587e+00,  2.73620069e-01,  2.33731863e-01,  5.44965578e-02,\n",
       "        1.17204654e-02, -2.20841756e-02,  7.98811510e-02, -1.23115710e-01,\n",
       "        4.52137460e-01, -8.59998452e-01,  4.75175093e+00,  9.31565346e-01,\n",
       "        9.10875724e-01,  2.73534715e-02,  6.24128059e-03, -3.89845480e-02,\n",
       "        1.40209730e-01, -6.91843688e-02,  2.48597865e-01, -1.55417260e+00,\n",
       "        2.75569617e+00,  1.04980295e+00,  1.03650562e+00,  1.94597503e-02,\n",
       "        3.96627251e-03, -3.35788530e-02,  1.21831372e-01, -4.39522220e-02,\n",
       "        1.59468208e-01, -1.35007352e+00,  1.76714587e+00,  4.26043644e-01,\n",
       "        3.33216404e-01,  1.23120699e-01,  3.61190658e-02, -4.96240275e-02,\n",
       "        1.74239507e-01,  1.25795200e-01, -4.12812743e-01,  7.20503636e-01,\n",
       "        1.66108048e+00,  3.17992102e-01,  3.49033327e-01,  1.76170230e-01,\n",
       "        7.75444392e-02, -1.58742037e-01,  1.23212715e-01,  3.49135689e-01,\n",
       "       -2.88453019e-01,  5.44136086e-01,  1.22954019e+00,  4.28347842e-01,\n",
       "        3.30492074e-01,  1.23123359e-01, -3.26157175e-02, -4.31926088e-02,\n",
       "       -1.75926261e-01,  1.10728637e-01,  4.17346697e-01,  7.20123919e-01,\n",
       "        1.66108048e+00,  3.21184385e-01,  3.41993031e-01,  1.77012662e-01,\n",
       "       -7.87837637e-02, -1.54162709e-01, -1.28254775e-01,  3.39987737e-01,\n",
       "        3.00797120e-01,  5.41540989e-01,  1.22954019e+00, -6.84076360e-03,\n",
       "        9.21053669e-03,  9.50470552e-03, -4.15787824e-03,  3.59272395e-03,\n",
       "        9.69593440e-03, -6.62465076e-03,  1.50571617e-03,  1.57337414e-02,\n",
       "       -2.15429938e-03,  3.78276537e-03,  9.86148745e-03,  1.16677185e-03,\n",
       "        1.67272721e-03,  1.56802586e-02, -2.17597989e-03,  4.79072981e-03,\n",
       "        9.85062665e-03, -2.38936807e-03,  3.80244570e-03,  2.45350083e-02,\n",
       "       -3.03875599e-03,  5.02198138e-03,  9.44850876e-03, -2.33364155e-03,\n",
       "        6.44002482e-04,  2.45555066e-02, -4.28184579e-03,  5.00063106e-03,\n",
       "        9.53823858e-03, -2.33364155e-03,  6.44002482e-04,  2.45555066e-02,\n",
       "       -4.28184579e-03,  5.00063106e-03,  9.53823858e-03,  4.75286113e-03,\n",
       "        4.76476840e-03,  1.01804342e-02, -2.69266720e-03,  4.60606018e-03,\n",
       "        9.40990477e-03,  4.95768904e-03, -4.49700968e-03,  1.01793688e-02,\n",
       "       -6.34177039e-03,  4.52533398e-03,  9.62580020e-03,  4.95768904e-03,\n",
       "       -4.49700968e-03,  1.01793688e-02, -6.34177039e-03,  4.52533398e-03,\n",
       "        9.62580020e-03, -7.97208252e-03,  7.60038901e-03,  9.95661037e-03,\n",
       "       -3.40690821e-03,  3.01353006e-03,  9.51226499e-03, -7.99880208e-03,\n",
       "        8.70075877e-03,  8.84803833e-03, -3.38899939e-03,  3.20060734e-03,\n",
       "        9.69752644e-03, -1.73650502e-03,  1.09479898e-02,  1.61065282e-02,\n",
       "       -3.92784290e-03,  6.29366210e-03,  8.80725357e-03, -1.73088570e-03,\n",
       "        6.65053052e-03,  1.18288850e-02, -4.00856688e-03,  6.99671144e-03,\n",
       "        8.10084133e-03,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aff0a3e-a047-4da7-aead-28470aad0f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-0.4, 0.4, (17,), float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0d19bf1-44ae-4628-909d-8a529b9077e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05293579, -0.02909377,  0.12628955,  0.15863812, -0.14441639,\n",
       "       -0.0146535 , -0.04183137,  0.30172417, -0.05358713, -0.20124765,\n",
       "       -0.3164999 , -0.08170177, -0.13806766, -0.0086144 , -0.1124486 ,\n",
       "       -0.22309826,  0.36465538], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "865db760-7704-44a3-a5b8-7717a332cc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE 1 - Step:1, Reward:4.9, Total:4.9\n",
      "EPISODE 1 - Step:100, Reward:4.7, Total:467.3\n",
      "EPISODE 1 - Step:200, Reward:4.9, Total:951.0\n"
     ]
    }
   ],
   "source": [
    "# RANDOM ACTIONS\n",
    "import gymnasium as gym\n",
    "import time\n",
    "\n",
    "env = gym.make(\"Humanoid-v4\", render_mode=\"human\")\n",
    "obs, info = env.reset()\n",
    "\n",
    "reset = False #reset if the humanoid falls or the episode ends\n",
    "episode = 1\n",
    "total_reward, step = 0, 0\n",
    "\n",
    "for _ in range(240):\n",
    "    ## action\n",
    "    step += 1\n",
    "    action = env.action_space.sample() #random action\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    ## reward\n",
    "    total_reward += reward\n",
    "    ## render\n",
    "    env.render() #render physics step (CPU speed = 0.1 seconds)\n",
    "    time.sleep(1/240) #slow down to real-time (240 steps × 1/240 second sleep = 1 second)\n",
    "    if (step == 1) or (step % 100 == 0): #print first step and every 100 steps\n",
    "        print(f\"EPISODE {episode} - Step:{step}, Reward:{reward:.1f}, Total:{total_reward:.1f}\")\n",
    "    ## reset\n",
    "    if reset:\n",
    "        if terminated or truncated: #print the last step\n",
    "            print(f\"EPISODE {episode} - Step:{step}, Reward:{reward:.1f}, Total:{total_reward:.1f}\")\n",
    "            obs, info = env.reset()\n",
    "            episode += 1\n",
    "            total_reward, step = 0, 0\n",
    "            print(\"------------------------------------------\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05289fe9-8ac4-4158-b76f-23f4c9cf3b64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e58dc0b4-5b6e-402d-b8e6-c732aba106bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WindowViewer.__del__ at 0x7fd4ce8e15f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 335, in __del__\n",
      "    self.free()\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 330, in free\n",
      "    glfw.destroy_window(self.window)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/glfw/__init__.py\", line 1282, in destroy_window\n",
      "    window_addr = ctypes.cast(ctypes.pointer(window),\n",
      "TypeError: _type_ must have storage info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE 1 - Step:1, Reward:4.7, Total:4.7\n",
      "EPISODE 1 - Step:20, Reward:5.6, Total:96.8\n",
      "------------------------------------------\n",
      "EPISODE 2 - Step:1, Reward:4.6, Total:4.6\n",
      "EPISODE 2 - Step:37, Reward:5.0, Total:187.5\n",
      "------------------------------------------\n",
      "EPISODE 3 - Step:1, Reward:4.7, Total:4.7\n",
      "EPISODE 3 - Step:53, Reward:5.9, Total:279.8\n",
      "------------------------------------------\n",
      "EPISODE 4 - Step:1, Reward:4.9, Total:4.9\n",
      "EPISODE 4 - Step:33, Reward:6.2, Total:179.3\n",
      "------------------------------------------\n",
      "EPISODE 5 - Step:1, Reward:4.9, Total:4.9\n",
      "EPISODE 5 - Step:37, Reward:6.2, Total:203.6\n",
      "------------------------------------------\n",
      "EPISODE 6 - Step:1, Reward:4.9, Total:4.9\n",
      "EPISODE 6 - Step:42, Reward:6.2, Total:230.4\n",
      "------------------------------------------\n",
      "EPISODE 7 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 7 - Step:41, Reward:6.3, Total:224.2\n",
      "------------------------------------------\n",
      "EPISODE 8 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 8 - Step:34, Reward:6.2, Total:186.7\n",
      "------------------------------------------\n",
      "EPISODE 9 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 9 - Step:38, Reward:6.3, Total:211.8\n",
      "------------------------------------------\n",
      "EPISODE 10 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 10 - Step:36, Reward:6.2, Total:197.7\n",
      "------------------------------------------\n",
      "EPISODE 11 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 11 - Step:42, Reward:5.9, Total:217.9\n",
      "------------------------------------------\n",
      "EPISODE 12 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 12 - Step:34, Reward:6.1, Total:182.4\n",
      "------------------------------------------\n",
      "EPISODE 13 - Step:1, Reward:4.9, Total:4.9\n",
      "EPISODE 13 - Step:34, Reward:6.3, Total:186.9\n",
      "------------------------------------------\n",
      "EPISODE 14 - Step:1, Reward:4.9, Total:4.9\n",
      "EPISODE 14 - Step:38, Reward:6.4, Total:211.3\n",
      "------------------------------------------\n",
      "EPISODE 15 - Step:1, Reward:4.9, Total:4.9\n",
      "EPISODE 15 - Step:36, Reward:6.4, Total:200.9\n",
      "------------------------------------------\n",
      "EPISODE 16 - Step:1, Reward:4.9, Total:4.9\n",
      "EPISODE 16 - Step:37, Reward:6.4, Total:204.9\n",
      "------------------------------------------\n",
      "EPISODE 17 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 17 - Step:37, Reward:6.4, Total:204.3\n",
      "------------------------------------------\n",
      "EPISODE 18 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 18 - Step:37, Reward:6.2, Total:201.1\n",
      "------------------------------------------\n",
      "EPISODE 19 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 19 - Step:36, Reward:6.1, Total:193.5\n",
      "------------------------------------------\n",
      "EPISODE 20 - Step:1, Reward:4.9, Total:4.9\n",
      "EPISODE 20 - Step:42, Reward:6.2, Total:230.0\n",
      "------------------------------------------\n",
      "EPISODE 21 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 21 - Step:39, Reward:6.2, Total:213.2\n",
      "------------------------------------------\n",
      "EPISODE 22 - Step:1, Reward:4.9, Total:4.9\n",
      "EPISODE 22 - Step:40, Reward:6.2, Total:217.3\n",
      "------------------------------------------\n",
      "EPISODE 23 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 23 - Step:50, Reward:5.7, Total:257.6\n",
      "------------------------------------------\n",
      "EPISODE 24 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 24 - Step:40, Reward:5.1, Total:198.2\n",
      "------------------------------------------\n",
      "EPISODE 25 - Step:1, Reward:4.9, Total:4.9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_z/cl6cx94516g2tlbhzcbl4nfc0000gn/T/ipykernel_63924/848025175.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mexploration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexploration_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#add random noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_action\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mexploration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m## reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/gymnasium/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/gymnasium/wrappers/order_enforcing.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mResetNeeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot call env.step() before calling env.reset()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/gymnasium/wrappers/env_checker.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0menv_step_passive_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/gymnasium/envs/mujoco/humanoid_v4.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"human\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/gymnasium/envs/mujoco/mujoco_env.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         return self.mujoco_renderer.render(\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcamera_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcamera_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         )\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, render_mode, camera_id, camera_name)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mrender_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"human\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_viewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_mode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loop_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loop_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m                 \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loop_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    392\u001b[0m                     )\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0mglfw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswap_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m             \u001b[0mglfw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             self._time_per_render = 0.9 * self._time_per_render + 0.1 * (\n",
      "\u001b[0;32m~/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/glfw/__init__.py\u001b[0m in \u001b[0;36mswap_buffers\u001b[0;34m(window)\u001b[0m\n\u001b[1;32m   2378\u001b[0m         \u001b[0mvoid\u001b[0m \u001b[0mglfwSwapBuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGLFWwindow\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2379\u001b[0m     \"\"\"\n\u001b[0;32m-> 2380\u001b[0;31m     \u001b[0m_glfw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglfwSwapBuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2382\u001b[0m \u001b[0m_glfw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglfwSwapInterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/glfw/__init__.py\u001b[0m in \u001b[0;36merrcheck\u001b[0;34m(result, *args)\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0musing\u001b[0m \u001b[0mthe\u001b[0m \u001b[0m_callback_exception_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m     \"\"\"\n\u001b[0;32m--> 687\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0merrcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         \u001b[0;32mglobal\u001b[0m \u001b[0m_exc_info_from_callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_exc_info_from_callback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make(\"Humanoid-v4\", render_mode=\"human\")\n",
    "obs, info = env.reset()\n",
    "\n",
    "reset = True #reset if the humanoid falls or the episode ends\n",
    "episode = 1\n",
    "total_reward, step = 0, 0\n",
    "exploration_rate = 0.5 #start wild\n",
    "preferred_action = np.zeros(env.action_space.shape) #knowledge to update with experience\n",
    "\n",
    "for _ in range(1000):\n",
    "    ## action\n",
    "    step += 1\n",
    "    exploration = np.random.normal(loc=0, scale=exploration_rate, size=env.action_space.shape) #add random noise\n",
    "    action = np.clip(a=preferred_action+exploration, a_min=-1, a_max=1)\n",
    "    obs, reward, terminated, truncated, info = env.step(action) \n",
    "    ## reward\n",
    "    total_reward += reward\n",
    "    if reward > 0:\n",
    "        preferred_action += (action-preferred_action)*0.05 #learning_rate\n",
    "    exploration_rate = max(0.05, exploration_rate*0.99) #min_exploration=0.05, decay_exploration=0.99\n",
    "    ## render\n",
    "    env.render() \n",
    "    time.sleep(1/240)\n",
    "    if (step == 1) or (step % 100 == 0):\n",
    "        print(f\"EPISODE {episode} - Step:{step}, Reward:{reward:.1f}, Total:{total_reward:.1f}\")\n",
    "    ## reset\n",
    "    if reset:\n",
    "        if terminated or truncated:\n",
    "            print(f\"EPISODE {episode} - Step:{step}, Reward:{reward:.1f}, Total:{total_reward:.1f}\")\n",
    "            obs, info = env.reset()\n",
    "            episode += 1\n",
    "            total_reward, step = 0, 0\n",
    "            print(\"------------------------------------------\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8942f3a-53fc-4cb3-b1e5-f762ef5fc827",
   "metadata": {},
   "source": [
    "### Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93365d2f",
   "metadata": {},
   "source": [
    "###### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4ebf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training START\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/_z/cl6cx94516g2tlbhzcbl4nfc0000gn/T/ipykernel_66008/1198057625.py\", line 19, in <module>\n",
      "    tb_log_name=\"model_humanoid\", log_interval=10)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\", line 313, in learn\n",
      "    progress_bar=progress_bar,\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/stable_baselines3/common/off_policy_algorithm.py\", line 331, in learn\n",
      "    self.train(batch_size=self.batch_size, gradient_steps=gradient_steps)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\", line 215, in train\n",
      "    replay_data = self.replay_buffer.sample(batch_size, env=self._vec_normalize_env)  # type: ignore[union-attr]\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/stable_baselines3/common/buffers.py\", line 285, in sample\n",
      "    return super().sample(batch_size=batch_size, env=env)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/stable_baselines3/common/buffers.py\", line 111, in sample\n",
      "    return self._get_samples(batch_inds, env=env)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/stable_baselines3/common/buffers.py\", line 301, in _get_samples\n",
      "    next_obs = self._normalize_obs(self.next_observations[batch_inds, env_indices, :], env)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/_z/cl6cx94516g2tlbhzcbl4nfc0000gn/T/ipykernel_66008/1198057625.py\", line 19, in <module>\n",
      "    tb_log_name=\"model_humanoid\", log_interval=10)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\", line 313, in learn\n",
      "    progress_bar=progress_bar,\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/stable_baselines3/common/off_policy_algorithm.py\", line 331, in learn\n",
      "    self.train(batch_size=self.batch_size, gradient_steps=gradient_steps)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\", line 215, in train\n",
      "    replay_data = self.replay_buffer.sample(batch_size, env=self._vec_normalize_env)  # type: ignore[union-attr]\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/stable_baselines3/common/buffers.py\", line 285, in sample\n",
      "    return super().sample(batch_size=batch_size, env=env)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/stable_baselines3/common/buffers.py\", line 111, in sample\n",
      "    return self._get_samples(batch_inds, env=env)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/stable_baselines3/common/buffers.py\", line 301, in _get_samples\n",
      "    next_obs = self._normalize_obs(self.next_observations[batch_inds, env_indices, :], env)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/posixpath.py\", line 396, in realpath\n",
      "    return abspath(path)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/posixpath.py\", line 385, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/posixpath.py\", line 359, in normpath\n",
      "    comps = path.split(sep)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/_z/cl6cx94516g2tlbhzcbl4nfc0000gn/T/ipykernel_66008/1198057625.py\", line 19, in <module>\n",
      "    tb_log_name=\"model_humanoid\", log_interval=10)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\", line 313, in learn\n",
      "    progress_bar=progress_bar,\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/stable_baselines3/common/off_policy_algorithm.py\", line 331, in learn\n",
      "    self.train(batch_size=self.batch_size, gradient_steps=gradient_steps)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\", line 215, in train\n",
      "    replay_data = self.replay_buffer.sample(batch_size, env=self._vec_normalize_env)  # type: ignore[union-attr]\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/stable_baselines3/common/buffers.py\", line 285, in sample\n",
      "    return super().sample(batch_size=batch_size, env=env)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/stable_baselines3/common/buffers.py\", line 111, in sample\n",
      "    return self._get_samples(batch_inds, env=env)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/stable_baselines3/common/buffers.py\", line 301, in _get_samples\n",
      "    next_obs = self._normalize_obs(self.next_observations[batch_inds, env_indices, :], env)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1143, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/posixpath.py\", line 174, in islink\n",
      "    return stat.S_ISLNK(st.st_mode)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "#pip install torch\n",
    "#pip install stable-baselines3\n",
    "#pip install tensorboard\n",
    "\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "## environment\n",
    "env = gym.make(\"Humanoid-v4\") #no rendering to speed up\n",
    "env = DummyVecEnv([lambda:env])\n",
    "\n",
    "## train\n",
    "print(\"Training START\")\n",
    "model = SAC(policy=\"MlpPolicy\", env=env, verbose=0, \n",
    "            learning_rate=0.005, ent_coef=0.005, #exploration\n",
    "            tensorboard_log=\"logs/\") #>tensorboard --logdir=logs/\n",
    "model.learn(total_timesteps=500_000, #1h\n",
    "            tb_log_name=\"model_humanoid\", log_interval=10)\n",
    "print(\"Training DONE\")\n",
    "\n",
    "## save\n",
    "model.save(\"model_humanoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eb8d555-7b8d-4aff-9575-67d36e392ab8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training START\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WindowViewer.__del__ at 0x7fef22e7e0e0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 335, in __del__\n",
      "    self.free()\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 330, in free\n",
      "    glfw.destroy_window(self.window)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/glfw/__init__.py\", line 1282, in destroy_window\n",
      "    window_addr = ctypes.cast(ctypes.pointer(window),\n",
      "TypeError: _type_ must have storage info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DONE\n"
     ]
    }
   ],
   "source": [
    "#pip install torch\n",
    "#pip install stable-baselines3\n",
    "#pip install tensorboard\n",
    "\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "## environment\n",
    "env = gym.make(\"Humanoid-v4\") #no rendering to speed up\n",
    "env = DummyVecEnv([lambda:env])\n",
    "\n",
    "## train\n",
    "print(\"Training START\")\n",
    "model = PPO(policy=\"MlpPolicy\", env=env, verbose=0, \n",
    "            learning_rate=0.005, ent_coef=0.005, #exploration\n",
    "            tensorboard_log=\"logs/\") #>tensorboard --logdir=logs/\n",
    "model.learn(total_timesteps=3_000_000, #1h\n",
    "            tb_log_name=\"model_humanoid\", log_interval=10)\n",
    "print(\"Training DONE\")\n",
    "\n",
    "## save\n",
    "model.save(\"model_humanoid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d669646",
   "metadata": {},
   "source": [
    "###### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a132979e-2f8d-4cb6-a905-0071520f5f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE 1 - Step:1, Reward:4.7, Total:4.7\n",
      "EPISODE 1 - Step:100, Reward:5.8, Total:509.3\n",
      "EPISODE 1 - Step:200, Reward:4.6, Total:1014.7\n",
      "EPISODE 1 - Step:300, Reward:4.9, Total:1478.7\n",
      "EPISODE 1 - Step:400, Reward:4.6, Total:1941.6\n",
      "EPISODE 1 - Step:500, Reward:4.7, Total:2404.6\n",
      "EPISODE 1 - Step:600, Reward:4.7, Total:2879.2\n",
      "EPISODE 1 - Step:700, Reward:4.6, Total:3344.9\n",
      "EPISODE 1 - Step:800, Reward:4.5, Total:3816.8\n",
      "EPISODE 1 - Step:900, Reward:4.7, Total:4287.6\n",
      "EPISODE 1 - Step:1000, Reward:4.5, Total:4749.2\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "import time\n",
    "\n",
    "env = gym.make(\"Humanoid-v4\", render_mode=\"human\")\n",
    "model = PPO.load(path=\"model_humanoid\", env=env)\n",
    "obs, info = env.reset()\n",
    "\n",
    "reset = False #reset if the humanoid falls or the episode ends\n",
    "episode = 1\n",
    "total_reward, step = 0, 0\n",
    "\n",
    "for _ in range(1000):\n",
    "    ## action\n",
    "    step += 1\n",
    "    action, _ = model.predict(obs)    \n",
    "    obs, reward, terminated, truncated, info = env.step(action) \n",
    "    ## reward\n",
    "    total_reward += reward\n",
    "    ## render\n",
    "    env.render() \n",
    "    time.sleep(1/240)\n",
    "    if (step == 1) or (step % 100 == 0): #print first step and every 100 steps\n",
    "        print(f\"EPISODE {episode} - Step:{step}, Reward:{reward:.1f}, Total:{total_reward:.1f}\")\n",
    "    ## reset\n",
    "    if reset:\n",
    "        if terminated or truncated: #print the last step\n",
    "            print(f\"EPISODE {episode} - Step:{step}, Reward:{reward:.1f}, Total:{total_reward:.1f}\")\n",
    "            obs, info = env.reset()\n",
    "            episode += 1\n",
    "            total_reward, step = 0, 0\n",
    "            print(\"------------------------------------------\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b667fe",
   "metadata": {},
   "source": [
    "### Custom Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "203263a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mujoco_py' has no attribute 'load_model_from_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_z/cl6cx94516g2tlbhzcbl4nfc0000gn/T/ipykernel_74256/1973694850.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# 🔹 Test the env (random actions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AntJump-v1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"human\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0menv_spec_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         if (\n",
      "\u001b[0;32m/var/folders/_z/cl6cx94516g2tlbhzcbl4nfc0000gn/T/ipykernel_74256/1973694850.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m  \u001b[0;31m# what counts as a good jump\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/gymnasium/envs/mujoco/ant.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         )\n\u001b[1;32m     22\u001b[0m         MuJocoPyEnv.__init__(\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ant.xml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         )\n\u001b[1;32m     25\u001b[0m         \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEzPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/gymnasium/envs/mujoco/mujoco_env.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, frame_skip, observation_space, render_mode, width, height, camera_id, camera_name)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mcamera_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mcamera_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         )\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/gymnasium/envs/mujoco/mujoco_env.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, frame_skip, observation_space, render_mode, width, height, camera_id, camera_name)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may use width and height\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_qpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/gymnasium/envs/mujoco/mujoco_env.py\u001b[0m in \u001b[0;36m_initialize_simulation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_initialize_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmujoco_py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfullpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmujoco_py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMjSim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'mujoco_py' has no attribute 'load_model_from_path'"
     ]
    }
   ],
   "source": [
    "# pip install gymnasium[mujoco] stable-baselines3 mujoco glfw\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium.envs.mujoco import AntEnv\n",
    "from gymnasium.envs.registration import register\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class AntJumpEnv(AntEnv):\n",
    "    \"\"\"Custom Ant that learns to JUMP instead of walk.\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.target_height = 0.8  # what counts as a good jump\n",
    "        self.last_z = None\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = super().step(action)\n",
    "\n",
    "        # get torso height (z position of the main body)\n",
    "        torso_height = float(self.data.qpos[2])\n",
    "\n",
    "        # --- 💥 custom reward ---\n",
    "        # reward for jumping high\n",
    "        jump_bonus = np.clip(torso_height - 0.6, 0, 1) * 10.0\n",
    "        # penalize wasting energy\n",
    "        ctrl_penalty = 0.05 * np.square(action).sum()\n",
    "\n",
    "        reward = jump_bonus - ctrl_penalty\n",
    "\n",
    "        # episode ends if it falls\n",
    "        terminated = bool(torso_height < 0.2)\n",
    "\n",
    "        info[\"torso_height\"] = torso_height\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    def reset_model(self):\n",
    "        obs, info = super().reset_model()\n",
    "        self.last_z = self.data.qpos[2]\n",
    "        return obs, info\n",
    "\n",
    "\n",
    "# 🔹 Register it so Gym can find it\n",
    "register(\n",
    "    id=\"AntJump-v1\",\n",
    "    entry_point=\"__main__:AntJumpEnv\",\n",
    ")\n",
    "\n",
    "# 🔹 Test the env (random actions)\n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make(\"AntJump-v1\", render_mode=\"human\")\n",
    "    obs, info = env.reset(seed=42)\n",
    "\n",
    "    for step in range(1000):\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        if terminated or truncated:\n",
    "            obs, info = env.reset()\n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7397fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
