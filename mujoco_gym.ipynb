{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f91ab3c1-1426-4321-a39f-6cdfd823f91b",
   "metadata": {},
   "source": [
    "# Robotics with Python: MuJoCo & Gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ae8c9e-1ca3-4c28-92db-1983f73b2ec2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec626f0d-ed53-4a61-9dd0-3db68228373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install mujoco\n",
    "#pip install gymnasium\n",
    "\n",
    "import gymnasium as gym\n",
    "import time\n",
    "\n",
    "env = gym.make(\"Humanoid-v4\", render_mode=\"human\")\n",
    "obs, info = env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6518852-f8f7-47bc-9c3a-b04fb9009e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_position': np.float64(0.0016152704880662335),\n",
       " 'y_position': np.float64(-0.006376264384969079),\n",
       " 'tendon_length': array([ 0.0039346 , -0.00659782]),\n",
       " 'tendon_velocity': array([-0.00065977,  0.00110333]),\n",
       " 'distance_from_origin': np.float64(0.006577677877233183)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed678fa4-f2a3-4d06-ad04-70f2e0fa6b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.40551438e+00,  1.00249109e+00,  1.02295992e-03,  6.11636741e-03,\n",
       "        8.89343991e-03,  3.68799654e-03,  2.68748631e-03, -7.37148320e-03,\n",
       "       -1.27035634e-03, -3.83448487e-03,  4.97995726e-03, -9.27465782e-04,\n",
       "       -5.30276103e-03, -6.80604484e-04, -9.18529355e-03, -1.14950454e-03,\n",
       "       -7.01506517e-03,  3.62228355e-03,  8.04498421e-03, -5.30207130e-03,\n",
       "       -1.90562795e-03, -6.06947519e-05,  2.28593828e-05,  6.61675641e-03,\n",
       "        9.77447190e-03, -6.79145658e-03,  9.35076611e-03,  9.40259276e-03,\n",
       "        6.24602486e-03, -7.69409031e-03,  7.79339588e-03, -3.57860426e-03,\n",
       "        8.84452451e-03,  2.14833940e-03,  3.15900130e-03, -3.69123743e-03,\n",
       "        5.47496853e-03,  3.01387670e-03,  9.26404279e-03, -1.41988753e-03,\n",
       "        1.43547743e-03, -1.56219701e-03,  6.16717799e-03,  5.88406125e-03,\n",
       "        6.06353189e-03,  2.30359698e+00,  2.28564819e+00,  4.23921394e-02,\n",
       "        3.81892603e-04,  4.27251199e-02, -1.34221053e-03, -9.78046855e-02,\n",
       "        3.05445261e-03,  4.35635947e+00,  8.90746237e+00,  9.54401200e-02,\n",
       "        9.04533260e-02,  1.09705672e-02,  1.69755818e-04,  9.77440278e-03,\n",
       "       -3.54790130e-04, -5.02470996e-02,  1.75551967e-03,  4.39996214e-01,\n",
       "        2.26194671e+00,  5.81292177e-02,  4.29646789e-02,  6.51220250e-02,\n",
       "        5.80889417e-04,  8.63263977e-03,  1.58756505e-04, -2.91065012e-01,\n",
       "       -4.52640715e-04,  1.96299323e-01,  6.61619413e+00,  2.72599949e-01,\n",
       "        2.31594969e-01,  5.48173694e-02, -1.10165227e-02, -2.15081603e-02,\n",
       "       -8.05523997e-02, -1.14986334e-01, -4.56016698e-01, -8.55144168e-01,\n",
       "        4.75175093e+00,  9.30058281e-01,  9.08257704e-01,  2.96113625e-02,\n",
       "       -7.45843650e-03, -4.52459751e-02, -1.45304611e-01, -7.97117497e-02,\n",
       "       -2.57757649e-01, -1.55134593e+00,  2.75569617e+00,  1.04849763e+00,\n",
       "        1.03433793e+00,  2.16319803e-02, -5.27336804e-03, -4.24042258e-02,\n",
       "       -1.27917885e-01, -5.55800809e-02, -1.67664573e-01, -1.34822496e+00,\n",
       "        1.76714587e+00,  2.73620069e-01,  2.33731863e-01,  5.44965578e-02,\n",
       "        1.17204654e-02, -2.20841756e-02,  7.98811510e-02, -1.23115710e-01,\n",
       "        4.52137460e-01, -8.59998452e-01,  4.75175093e+00,  9.31565346e-01,\n",
       "        9.10875724e-01,  2.73534715e-02,  6.24128059e-03, -3.89845480e-02,\n",
       "        1.40209730e-01, -6.91843688e-02,  2.48597865e-01, -1.55417260e+00,\n",
       "        2.75569617e+00,  1.04980295e+00,  1.03650562e+00,  1.94597503e-02,\n",
       "        3.96627251e-03, -3.35788530e-02,  1.21831372e-01, -4.39522220e-02,\n",
       "        1.59468208e-01, -1.35007352e+00,  1.76714587e+00,  4.26043644e-01,\n",
       "        3.33216404e-01,  1.23120699e-01,  3.61190658e-02, -4.96240275e-02,\n",
       "        1.74239507e-01,  1.25795200e-01, -4.12812743e-01,  7.20503636e-01,\n",
       "        1.66108048e+00,  3.17992102e-01,  3.49033327e-01,  1.76170230e-01,\n",
       "        7.75444392e-02, -1.58742037e-01,  1.23212715e-01,  3.49135689e-01,\n",
       "       -2.88453019e-01,  5.44136086e-01,  1.22954019e+00,  4.28347842e-01,\n",
       "        3.30492074e-01,  1.23123359e-01, -3.26157175e-02, -4.31926088e-02,\n",
       "       -1.75926261e-01,  1.10728637e-01,  4.17346697e-01,  7.20123919e-01,\n",
       "        1.66108048e+00,  3.21184385e-01,  3.41993031e-01,  1.77012662e-01,\n",
       "       -7.87837637e-02, -1.54162709e-01, -1.28254775e-01,  3.39987737e-01,\n",
       "        3.00797120e-01,  5.41540989e-01,  1.22954019e+00, -6.84076360e-03,\n",
       "        9.21053669e-03,  9.50470552e-03, -4.15787824e-03,  3.59272395e-03,\n",
       "        9.69593440e-03, -6.62465076e-03,  1.50571617e-03,  1.57337414e-02,\n",
       "       -2.15429938e-03,  3.78276537e-03,  9.86148745e-03,  1.16677185e-03,\n",
       "        1.67272721e-03,  1.56802586e-02, -2.17597989e-03,  4.79072981e-03,\n",
       "        9.85062665e-03, -2.38936807e-03,  3.80244570e-03,  2.45350083e-02,\n",
       "       -3.03875599e-03,  5.02198138e-03,  9.44850876e-03, -2.33364155e-03,\n",
       "        6.44002482e-04,  2.45555066e-02, -4.28184579e-03,  5.00063106e-03,\n",
       "        9.53823858e-03, -2.33364155e-03,  6.44002482e-04,  2.45555066e-02,\n",
       "       -4.28184579e-03,  5.00063106e-03,  9.53823858e-03,  4.75286113e-03,\n",
       "        4.76476840e-03,  1.01804342e-02, -2.69266720e-03,  4.60606018e-03,\n",
       "        9.40990477e-03,  4.95768904e-03, -4.49700968e-03,  1.01793688e-02,\n",
       "       -6.34177039e-03,  4.52533398e-03,  9.62580020e-03,  4.95768904e-03,\n",
       "       -4.49700968e-03,  1.01793688e-02, -6.34177039e-03,  4.52533398e-03,\n",
       "        9.62580020e-03, -7.97208252e-03,  7.60038901e-03,  9.95661037e-03,\n",
       "       -3.40690821e-03,  3.01353006e-03,  9.51226499e-03, -7.99880208e-03,\n",
       "        8.70075877e-03,  8.84803833e-03, -3.38899939e-03,  3.20060734e-03,\n",
       "        9.69752644e-03, -1.73650502e-03,  1.09479898e-02,  1.61065282e-02,\n",
       "       -3.92784290e-03,  6.29366210e-03,  8.80725357e-03, -1.73088570e-03,\n",
       "        6.65053052e-03,  1.18288850e-02, -4.00856688e-03,  6.99671144e-03,\n",
       "        8.10084133e-03,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aff0a3e-a047-4da7-aead-28470aad0f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-0.4, 0.4, (17,), float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0d19bf1-44ae-4628-909d-8a529b9077e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05293579, -0.02909377,  0.12628955,  0.15863812, -0.14441639,\n",
       "       -0.0146535 , -0.04183137,  0.30172417, -0.05358713, -0.20124765,\n",
       "       -0.3164999 , -0.08170177, -0.13806766, -0.0086144 , -0.1124486 ,\n",
       "       -0.22309826,  0.36465538], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "865db760-7704-44a3-a5b8-7717a332cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import time\n",
    "\n",
    "env = gym.make(\"Humanoid-v4\", render_mode=\"human\")\n",
    "obs, info = env.reset()\n",
    "\n",
    "reset = False #reset if the humanoid falls or the episode ends\n",
    "\n",
    "for step in range(240):\n",
    "    action = env.action_space.sample() #random action\n",
    "    obs, reward, terminated, truncated, info = env.step(action) #add a physics step (CPU speed = 0.1 seconds)\n",
    "    env.render() \n",
    "    time.sleep(1/240) #slow down to real-time (240 steps × 1/240 second sleep = 1 second)\n",
    "    if reset:\n",
    "        if terminated or truncated:\n",
    "            obs, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05289fe9-8ac4-4158-b76f-23f4c9cf3b64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81e6ea5-e6f0-4b1a-b9ae-358a02bd72a1",
   "metadata": {},
   "source": [
    "###### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92b8771e-ec28-473e-9220-adf5efc9cd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WindowViewer.__del__ at 0x7fa2c00ecf80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 335, in __del__\n",
      "    self.free()\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py\", line 330, in free\n",
      "    glfw.destroy_window(self.window)\n",
      "  File \"/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/glfw/__init__.py\", line 1282, in destroy_window\n",
      "    window_addr = ctypes.cast(ctypes.pointer(window),\n",
      "TypeError: _type_ must have storage info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE 1 - Step:1, Reward:4.9, Total:4.9\n",
      "EPISODE 1 - Step:100, Reward:4.9, Total:476.1\n",
      "EPISODE 1 - Step:200, Reward:4.8, Total:977.2\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import time\n",
    "\n",
    "env = gym.make(\"Humanoid-v4\", render_mode=\"human\")\n",
    "obs, info = env.reset()\n",
    "\n",
    "reset = False #reset if the humanoid falls or the episode ends\n",
    "episode = 1\n",
    "total_reward, step = 0, 0\n",
    "\n",
    "for _ in range(240):\n",
    "    ## action\n",
    "    step += 1\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    ## reward\n",
    "    total_reward += reward\n",
    "    ## render\n",
    "    env.render() \n",
    "    time.sleep(1/240)\n",
    "    if (step == 1) or (step % 100 == 0): #print first step and every 100 steps\n",
    "        print(f\"EPISODE {episode} - Step:{step}, Reward:{reward:.1f}, Total:{total_reward:.1f}\")\n",
    "    ## reset\n",
    "    if reset:\n",
    "        if terminated or truncated: #print the last step\n",
    "            print(f\"EPISODE {episode} - Step:{step}, Reward:{reward:.1f}, Total:{total_reward:.1f}\")\n",
    "            obs, info = env.reset()\n",
    "            episode += 1\n",
    "            total_reward, step = 0, 0\n",
    "            print(\"------------------------------------------\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d62cc6e-9b75-40f0-9e24-c0e2c5089dcb",
   "metadata": {},
   "source": [
    "###### Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e58dc0b4-5b6e-402d-b8e6-c732aba106bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE 1 - Step:1, Reward:4.7, Total:4.7\n",
      "EPISODE 1 - Step:17, Reward:4.7, Total:79.1\n",
      "------------------------------------------\n",
      "EPISODE 2 - Step:1, Reward:4.8, Total:4.8\n",
      "EPISODE 2 - Step:24, Reward:5.6, Total:120.9\n",
      "------------------------------------------\n",
      "EPISODE 3 - Step:1, Reward:4.8, Total:4.8\n",
      "EPISODE 3 - Step:17, Reward:4.8, Total:82.0\n",
      "------------------------------------------\n",
      "EPISODE 4 - Step:1, Reward:4.9, Total:4.9\n",
      "EPISODE 4 - Step:18, Reward:5.0, Total:87.9\n",
      "------------------------------------------\n",
      "EPISODE 5 - Step:1, Reward:4.9, Total:4.9\n",
      "EPISODE 5 - Step:18, Reward:5.1, Total:88.0\n",
      "------------------------------------------\n",
      "EPISODE 6 - Step:1, Reward:4.9, Total:4.9\n",
      "EPISODE 6 - Step:20, Reward:4.9, Total:98.2\n",
      "------------------------------------------\n",
      "EPISODE 7 - Step:1, Reward:4.9, Total:4.9\n",
      "EPISODE 7 - Step:17, Reward:4.9, Total:83.6\n",
      "------------------------------------------\n",
      "EPISODE 8 - Step:1, Reward:4.9, Total:4.9\n",
      "EPISODE 8 - Step:17, Reward:5.0, Total:84.0\n",
      "------------------------------------------\n",
      "EPISODE 9 - Step:1, Reward:4.9, Total:4.9\n",
      "EPISODE 9 - Step:21, Reward:5.1, Total:105.7\n",
      "------------------------------------------\n",
      "EPISODE 10 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 10 - Step:18, Reward:5.1, Total:90.1\n",
      "------------------------------------------\n",
      "EPISODE 11 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 11 - Step:19, Reward:5.2, Total:95.8\n",
      "------------------------------------------\n",
      "EPISODE 12 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 12 - Step:22, Reward:5.3, Total:112.0\n",
      "------------------------------------------\n",
      "EPISODE 13 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 13 - Step:24, Reward:5.3, Total:122.8\n",
      "------------------------------------------\n",
      "EPISODE 14 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 14 - Step:19, Reward:5.2, Total:95.6\n",
      "------------------------------------------\n",
      "EPISODE 15 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 15 - Step:22, Reward:5.2, Total:112.3\n",
      "------------------------------------------\n",
      "EPISODE 16 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 16 - Step:23, Reward:5.2, Total:117.0\n",
      "------------------------------------------\n",
      "EPISODE 17 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 17 - Step:23, Reward:5.2, Total:116.7\n",
      "------------------------------------------\n",
      "EPISODE 18 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 18 - Step:23, Reward:5.2, Total:117.0\n",
      "------------------------------------------\n",
      "EPISODE 19 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 19 - Step:23, Reward:5.2, Total:116.6\n",
      "------------------------------------------\n",
      "EPISODE 20 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 20 - Step:20, Reward:5.3, Total:101.6\n",
      "------------------------------------------\n",
      "EPISODE 21 - Step:1, Reward:5.0, Total:5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/glfw/__init__.py:917: GLFWError: (65537) b'The GLFW library is not initialized'\n",
      "  warnings.warn(message, GLFWError)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE 21 - Step:20, Reward:5.2, Total:101.1\n",
      "------------------------------------------\n",
      "EPISODE 22 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 22 - Step:20, Reward:5.2, Total:101.5\n",
      "------------------------------------------\n",
      "EPISODE 23 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 23 - Step:18, Reward:5.2, Total:90.5\n",
      "------------------------------------------\n",
      "EPISODE 24 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 24 - Step:23, Reward:5.3, Total:117.7\n",
      "------------------------------------------\n",
      "EPISODE 25 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 25 - Step:23, Reward:5.3, Total:117.8\n",
      "------------------------------------------\n",
      "EPISODE 26 - Step:1, Reward:4.9, Total:4.9\n",
      "EPISODE 26 - Step:19, Reward:5.3, Total:96.4\n",
      "------------------------------------------\n",
      "EPISODE 27 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 27 - Step:19, Reward:5.3, Total:96.4\n",
      "------------------------------------------\n",
      "EPISODE 28 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 28 - Step:20, Reward:5.3, Total:101.7\n",
      "------------------------------------------\n",
      "EPISODE 29 - Step:1, Reward:4.9, Total:4.9\n",
      "EPISODE 29 - Step:19, Reward:5.3, Total:96.4\n",
      "------------------------------------------\n",
      "EPISODE 30 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 30 - Step:18, Reward:5.3, Total:90.9\n",
      "------------------------------------------\n",
      "EPISODE 31 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 31 - Step:19, Reward:5.3, Total:96.6\n",
      "------------------------------------------\n",
      "EPISODE 32 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 32 - Step:20, Reward:5.3, Total:102.0\n",
      "------------------------------------------\n",
      "EPISODE 33 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 33 - Step:23, Reward:5.3, Total:117.6\n",
      "------------------------------------------\n",
      "EPISODE 34 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 34 - Step:21, Reward:5.3, Total:107.2\n",
      "------------------------------------------\n",
      "EPISODE 35 - Step:1, Reward:4.9, Total:4.9\n",
      "EPISODE 35 - Step:21, Reward:5.3, Total:106.9\n",
      "------------------------------------------\n",
      "EPISODE 36 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 36 - Step:19, Reward:5.3, Total:96.4\n",
      "------------------------------------------\n",
      "EPISODE 37 - Step:1, Reward:4.9, Total:4.9\n",
      "EPISODE 37 - Step:20, Reward:5.3, Total:101.6\n",
      "------------------------------------------\n",
      "EPISODE 38 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 38 - Step:20, Reward:5.3, Total:101.7\n",
      "------------------------------------------\n",
      "EPISODE 39 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 39 - Step:20, Reward:5.3, Total:101.6\n",
      "------------------------------------------\n",
      "EPISODE 40 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 40 - Step:22, Reward:5.4, Total:112.9\n",
      "------------------------------------------\n",
      "EPISODE 41 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 41 - Step:22, Reward:5.3, Total:113.2\n",
      "------------------------------------------\n",
      "EPISODE 42 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 42 - Step:20, Reward:5.4, Total:101.9\n",
      "------------------------------------------\n",
      "EPISODE 43 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 43 - Step:26, Reward:5.3, Total:133.8\n",
      "------------------------------------------\n",
      "EPISODE 44 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 44 - Step:23, Reward:5.3, Total:118.6\n",
      "------------------------------------------\n",
      "EPISODE 45 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 45 - Step:20, Reward:5.4, Total:102.4\n",
      "------------------------------------------\n",
      "EPISODE 46 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 46 - Step:22, Reward:5.4, Total:113.5\n",
      "------------------------------------------\n",
      "EPISODE 47 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 47 - Step:25, Reward:5.3, Total:129.1\n",
      "------------------------------------------\n",
      "EPISODE 48 - Step:1, Reward:5.0, Total:5.0\n",
      "EPISODE 48 - Step:21, Reward:5.3, Total:107.5\n",
      "------------------------------------------\n",
      "EPISODE 49 - Step:1, Reward:4.9, Total:4.9\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make(\"Humanoid-v4\", render_mode=\"human\")\n",
    "obs, info = env.reset()\n",
    "\n",
    "reset = True #reset if the humanoid falls or the episode ends\n",
    "episode = 1\n",
    "total_reward, step = 0, 0\n",
    "exploration_rate = 0.5 #start wild\n",
    "preferred_action = np.zeros(env.action_space.shape) #knowledge to update with experience\n",
    "\n",
    "for _ in range(1000):\n",
    "    ## action\n",
    "    step += 1\n",
    "    exploration = np.random.normal(loc=0, scale=exploration_rate, size=env.action_space.shape) #add random noise\n",
    "    action = np.clip(a=preferred_action+exploration, a_min=-1, a_max=1)\n",
    "    obs, reward, terminated, truncated, info = env.step(action) \n",
    "    ## reward\n",
    "    total_reward += reward\n",
    "    if reward > 0:\n",
    "        preferred_action += (action-preferred_action)*0.05 #learning_rate\n",
    "    exploration_rate = max(0.05, exploration_rate*0.99) #min_exploration=0.05, decay_exploration=0.99\n",
    "    ## render\n",
    "    env.render() \n",
    "    time.sleep(1/240)\n",
    "    if (step == 1) or (step % 100 == 0): #print first step and every 100 steps\n",
    "        print(f\"EPISODE {episode} - Step:{step}, Reward:{reward:.1f}, Total:{total_reward:.1f}\")\n",
    "    ## reset\n",
    "    if reset:\n",
    "        if terminated or truncated: #print the last step\n",
    "            print(f\"EPISODE {episode} - Step:{step}, Reward:{reward:.1f}, Total:{total_reward:.1f}\")\n",
    "            obs, info = env.reset()\n",
    "            episode += 1\n",
    "            total_reward, step = 0, 0\n",
    "            print(\"------------------------------------------\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8942f3a-53fc-4cb3-b1e5-f762ef5fc827",
   "metadata": {},
   "source": [
    "### Artificial Intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7e53822",
   "metadata": {},
   "outputs": [],
   "source": [
    "?PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93365d2f",
   "metadata": {},
   "source": [
    "###### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eb8d555-7b8d-4aff-9575-67d36e392ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Training started...\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 29   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 69   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      " complete.\n"
     ]
    }
   ],
   "source": [
    "#pip install torch\n",
    "#pip install stable-baselines3\n",
    "\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "## environment with no rendering\n",
    "env = gym.make(\"Humanoid-v4\", render_mode=\"human\")\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "## train\n",
    "model = PPO(policy=\"MlpPolicy\", env=env, verbose=1, learning_rate=0.05)\n",
    "print(\"Training started...\")\n",
    "model.learn(total_timesteps=100)\n",
    "print(\" complete.\")\n",
    "\n",
    "## save\n",
    "model.save(\"humanoid_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d669646",
   "metadata": {},
   "source": [
    "###### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a132979e-2f8d-4cb6-a905-0071520f5f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "EPISODE 1 - Step:1, Reward:4.7, Total:4.7\n",
      "EPISODE 1 - Step:100, Reward:4.5, Total:401.3\n",
      "EPISODE 1 - Step:200, Reward:3.9, Total:858.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mdp/opt/anaconda3/envs/TORCH/lib/python3.7/site-packages/glfw/__init__.py:917: GLFWError: (65537) b'The GLFW library is not initialized'\n",
      "  warnings.warn(message, GLFWError)\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "import time\n",
    "\n",
    "env = gym.make(\"Humanoid-v4\", render_mode=\"human\")\n",
    "model = PPO.load(path=\"humanoid_model\", env=env)\n",
    "obs, info = env.reset()\n",
    "\n",
    "reset = False #reset if the humanoid falls or the episode ends\n",
    "episode = 1\n",
    "total_reward, step = 0, 0\n",
    "\n",
    "for _ in range(240):\n",
    "    ## action\n",
    "    step += 1\n",
    "    action, _ = model.predict(obs)    \n",
    "    obs, reward, terminated, truncated, info = env.step(action) \n",
    "    ## reward\n",
    "    total_reward += reward\n",
    "    ## render\n",
    "    env.render() \n",
    "    time.sleep(1/240)\n",
    "    if (step == 1) or (step % 100 == 0): #print first step and every 100 steps\n",
    "        print(f\"EPISODE {episode} - Step:{step}, Reward:{reward:.1f}, Total:{total_reward:.1f}\")\n",
    "    ## reset\n",
    "    if reset:\n",
    "        if terminated or truncated: #print the last step\n",
    "            print(f\"EPISODE {episode} - Step:{step}, Reward:{reward:.1f}, Total:{total_reward:.1f}\")\n",
    "            obs, info = env.reset()\n",
    "            episode += 1\n",
    "            total_reward, step = 0, 0\n",
    "            print(\"------------------------------------------\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9a3beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
